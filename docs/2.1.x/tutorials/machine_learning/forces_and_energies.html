<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Supervised Learning: Training an ML Force-field &mdash; DScribe 2.1.x documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/style.css?v=7d1ac55c" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=c41997dc"></script>
        <script src="../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script defer="defer" src="../../_static/js/versions.js?v=413e22da"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="../../about.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Unsupervised Learning: Clustering" href="clustering.html" />
    <link rel="prev" title="Valle-Oganov descriptor" href="../descriptors/valleoganov.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html">
            
              <img src="../../_static/logo.png" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                2.1.x
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../tutorials.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../tutorials.html#basics">Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials.html#descriptors">Descriptors</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../tutorials.html#machine-learning">Machine Learning</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Supervised Learning: Training an ML Force-field</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#setup">Setup</a></li>
<li class="toctree-l4"><a class="reference internal" href="#dataset-generation">Dataset generation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#training">Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#analysis">Analysis</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="clustering.html">Unsupervised Learning: Clustering</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials.html#visualization">Visualization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tutorials.html#similarity-analysis">Similarity Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contributing.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../publications.html">Publications</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../citing.html">Citing DScribe</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../about.html">About</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">DScribe</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../tutorials.html">Tutorials</a></li>
      <li class="breadcrumb-item active">Supervised Learning: Training an ML Force-field</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/tutorials/machine_learning/forces_and_energies.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="supervised-learning-training-an-ml-force-field">
<h1>Supervised Learning: Training an ML Force-field<a class="headerlink" href="#supervised-learning-training-an-ml-force-field" title="Link to this heading"></a></h1>
<p>This tutorial covers how descriptors can be effectively used as input for a
machine learning model that will predict energies and forces. There are several
design choices that you have to make when building a ML force-field: which ML
model, which descriptor, etc. In this tutorial we will use the following, very
simple setup:</p>
<blockquote>
<div><ul class="simple">
<li><p>Dataset of two atoms interacting through a Lennard-Jones potential. This
is pretty much as simple as it gets. Real systems will be much more
complicated thus requiring a more complicated machine learning model and
longer training times.</p></li>
<li><p>SOAP descriptor calculated directly between the two atoms. Once again
this is for simplicity and in real systems you would have many more
centers, possibly on top of each atom.</p></li>
<li><p>We will use a fully connected neural network to perform the prediction.
In principle any machine learning method will do, but neural networks can
very conveniently calculate the analytical derivatives of the output with
respect to the input. This allows us to train an energy prediction model
from which we will automatically get the forces as long as we also know
the derivatives of the descriptor with respect to the atomic positions.
This is exactly what the <code class="code docutils literal notranslate"><span class="pre">derivatives</span></code>-function provided by DScribe
returns (notice that DScribe does not yet provide these derivatives for
all descriptors).</p></li>
</ul>
</div></blockquote>
<section id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Link to this heading"></a></h2>
<p>We will use a dataset of feature vectors <span class="math notranslate nohighlight">\(\mathbf{D}\)</span>, their derivatives
<span class="math notranslate nohighlight">\(\nabla_{\mathbf{r_i}} \mathbf{D}\)</span> and the associated system energies <span class="math notranslate nohighlight">\(E\)</span> and
forces <span class="math notranslate nohighlight">\(\mathbf{F}\)</span> for training. We will use a neural network <span class="math notranslate nohighlight">\(f\)</span>
to predict the energies: <span class="math notranslate nohighlight">\(\hat{E} = f(\mathbf{D})\)</span>. Here
variables with a “hat” on top indicate predicted quantities to distinguish them
from the real values. The predicted forces can be directly computed as the
negative gradients with respect to the atomic positions. For example the force
for atom <span class="math notranslate nohighlight">\(i\)</span> can be computed as (using row vectors):</p>
<div class="math notranslate nohighlight">
\[\begin{split}\hat{\mathbf{F}}_i &amp;= - \nabla_{\mathbf{r_i}} f(\mathbf{D}) \\
             &amp;= - \nabla_{\mathbf{D}} f \cdot \nabla_{\mathbf{r_i}} \mathbf{D}\\
             &amp;= - \begin{bmatrix}
                    \frac{\partial f}{\partial D_1} &amp; \frac{\partial f}{\partial D_2} &amp; \dots
                  \end{bmatrix}
                    \begin{bmatrix}
                    \frac{\partial D_1}{\partial x_i} &amp; \frac{\partial D_1}{\partial y_i} &amp; \frac{\partial D_1}{\partial z_i}\\
                    \frac{\partial D_2}{\partial x_i} &amp; \frac{\partial D_2}{\partial y_i} &amp; \frac{\partial D_2}{\partial z_i}\\
                    \vdots &amp; \vdots &amp; \vdots \\
                  \end{bmatrix}\end{split}\]</div>
<p>In these equations <span class="math notranslate nohighlight">\(\nabla_{\mathbf{D}} f\)</span> is the derivative of the ML
model output with respect to the input descriptor. As mentioned before, neural
networks typically can output these derivatives analytically.
<span class="math notranslate nohighlight">\(\nabla_{\mathbf{r_i}} \mathbf{D}\)</span> is the descriptor derivative with
respect to an atomic position. DScribe provides these derivatives for the SOAP
descriptor. Notice that in the derivatives provided by DScribe last dimension
loops over the features. This makes calculating the involved dot products
faster in an environment that uses a row-major order, such as numpy or C/C++,
as the dot product is taken over the last, fastest dimension. But you can of
course organize the output in any way you like.</p>
<p>The loss function for the neural network will contain the sum of mean squared
error of both energies and forces. In order to better equalize the contribution
of these two properties in the loss function their values are scaled by their
variance in the training set.</p>
</section>
<section id="dataset-generation">
<h2>Dataset generation<a class="headerlink" href="#dataset-generation" title="Link to this heading"></a></h2>
<p>The following script generates our training dataset (full script in the GitHub
repository: <em>examples/forces_and_energies/dataset.py</em>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">ase</span>
<span class="kn">from</span> <span class="nn">ase.calculators.lj</span> <span class="kn">import</span> <span class="n">LennardJones</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">dscribe.descriptors</span> <span class="kn">import</span> <span class="n">SOAP</span>

<span class="c1"># Setting up the SOAP descriptor</span>
<span class="n">soap</span> <span class="o">=</span> <span class="n">SOAP</span><span class="p">(</span>
    <span class="n">species</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;H&quot;</span><span class="p">],</span>
    <span class="n">periodic</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">r_cut</span><span class="o">=</span><span class="mf">5.0</span><span class="p">,</span>
    <span class="n">sigma</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">n_max</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">l_max</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Generate dataset of Lennard-Jones energies and forces</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">traj</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">n_atoms</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">energies</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
<span class="n">forces</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_atoms</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">r</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">ase</span><span class="o">.</span><span class="n">Atoms</span><span class="p">(</span><span class="s1">&#39;HH&#39;</span><span class="p">,</span> <span class="n">positions</span> <span class="o">=</span> <span class="p">[[</span><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">d</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">d</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
    <span class="n">a</span><span class="o">.</span><span class="n">set_calculator</span><span class="p">(</span><span class="n">LennardJones</span><span class="p">(</span><span class="n">epsilon</span><span class="o">=</span><span class="mf">1.0</span> <span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">2.9</span><span class="p">))</span>
    <span class="n">traj</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="n">energies</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">get_total_energy</span><span class="p">()</span>
    <span class="n">forces</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">get_forces</span><span class="p">()</span>
	
<span class="c1"># Plot the energies to validate them</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">line</span><span class="p">,</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">energies</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Distance (Å)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Energy (eV)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Create the SOAP desciptors and their derivatives for all samples. One center</span>
<span class="c1"># is chosen to be directly between the atoms.</span>
<span class="n">derivatives</span><span class="p">,</span> <span class="n">descriptors</span> <span class="o">=</span> <span class="n">soap</span><span class="o">.</span><span class="n">derivatives</span><span class="p">(</span>
    <span class="n">traj</span><span class="p">,</span>
    <span class="n">centers</span><span class="o">=</span><span class="p">[[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">r</span><span class="p">),</span>
    <span class="n">method</span><span class="o">=</span><span class="s2">&quot;analytical&quot;</span>
<span class="p">)</span>

<span class="c1"># Save to disk for later training</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;r.npy&quot;</span><span class="p">,</span> <span class="n">r</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;E.npy&quot;</span><span class="p">,</span> <span class="n">energies</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;D.npy&quot;</span><span class="p">,</span> <span class="n">descriptors</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;dD_dr.npy&quot;</span><span class="p">,</span> <span class="n">derivatives</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;F.npy&quot;</span><span class="p">,</span> <span class="n">forces</span><span class="p">)</span>
</pre></div>
</div>
<p>The energies will look like this:</p>
<a class="reference internal image-reference" href="../../_images/lj.png"><img alt="Lennard-Jones energies" class="align-center" src="../../_images/lj.png" style="width: 90%;" /></a>
</section>
<section id="training">
<h2>Training<a class="headerlink" href="#training" title="Link to this heading"></a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The training code shown in this tutorial uses <a class="reference external" href="https://pytorch.org/">pytorch</a>, which you need to install if you wish to run this
example. You can find the full script at
<em>examples/forces_and_energies/training_pytorch.py</em>. Notice that there is
also an identical implementation using <a class="reference external" href="https://www.tensorflow.org/">tensorflow</a>, kindly provided by <a class="reference external" href="https://github.com/xScoschx">xScoschx</a>. It can be found under
<em>examples/forces_and_energies/training_tensorflow.py</em>.</p>
</div>
<p>Let us first load and prepare the dataset (full script in the GitHub
repository: <em>examples/forces_and_energies/training_pytorch.py</em>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>

<span class="c1"># Load the dataset</span>
<span class="n">D_numpy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;D.npy&quot;</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># We only have one SOAP center</span>
<span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">D_numpy</span><span class="o">.</span><span class="n">shape</span>
<span class="n">E_numpy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;E.npy&quot;</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span>
<span class="n">F_numpy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;F.npy&quot;</span><span class="p">)</span>
<span class="n">dD_dr_numpy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;dD_dr.npy&quot;</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span>  <span class="c1"># We only have one SOAP center</span>
<span class="n">r_numpy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;r.npy&quot;</span><span class="p">)</span>

<span class="c1"># Select equally spaced points for training</span>
<span class="n">n_train</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">r_numpy</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_train</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">D_train_full</span> <span class="o">=</span> <span class="n">D_numpy</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span class="n">E_train_full</span> <span class="o">=</span> <span class="n">E_numpy</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span class="n">F_train_full</span> <span class="o">=</span> <span class="n">F_numpy</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span class="n">r_train_full</span> <span class="o">=</span> <span class="n">r_numpy</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span class="n">dD_dr_train_full</span> <span class="o">=</span> <span class="n">dD_dr_numpy</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

<span class="c1"># Standardize input for improved learning. Fit is done only on training data,</span>
<span class="c1"># scaling is applied to both descriptors and their derivatives on training and</span>
<span class="c1"># test sets.</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">D_train_full</span><span class="p">)</span>
<span class="n">D_train_full</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">D_train_full</span><span class="p">)</span>
<span class="n">D_whole</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">D_numpy</span><span class="p">)</span>
<span class="n">dD_dr_whole</span> <span class="o">=</span> <span class="n">dD_dr_numpy</span> <span class="o">/</span> <span class="n">scaler</span><span class="o">.</span><span class="n">scale_</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">dD_dr_train_full</span> <span class="o">=</span> <span class="n">dD_dr_train_full</span> <span class="o">/</span> <span class="n">scaler</span><span class="o">.</span><span class="n">scale_</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

<span class="c1"># Calculate the variance of energy and force values for the training set. These</span>
<span class="c1"># are used to balance their contribution to the MSE loss</span>
<span class="n">var_energy_train</span> <span class="o">=</span> <span class="n">E_train_full</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>
<span class="n">var_force_train</span> <span class="o">=</span> <span class="n">F_train_full</span><span class="o">.</span><span class="n">var</span><span class="p">()</span>

<span class="c1"># Subselect 20% of validation points for early stopping.</span>
<span class="n">D_train</span><span class="p">,</span> <span class="n">D_valid</span><span class="p">,</span> <span class="n">E_train</span><span class="p">,</span> <span class="n">E_valid</span><span class="p">,</span> <span class="n">F_train</span><span class="p">,</span> <span class="n">F_valid</span><span class="p">,</span> <span class="n">dD_dr_train</span><span class="p">,</span> <span class="n">dD_dr_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">D_train_full</span><span class="p">,</span>
    <span class="n">E_train_full</span><span class="p">,</span>
    <span class="n">F_train_full</span><span class="p">,</span>
    <span class="n">dD_dr_train_full</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Create tensors for pytorch</span>
<span class="n">D_whole</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">D_whole</span><span class="p">)</span>
<span class="n">D_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">D_train</span><span class="p">)</span>
<span class="n">D_valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">D_valid</span><span class="p">)</span>
<span class="n">E_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">E_train</span><span class="p">)</span>
<span class="n">E_valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">E_valid</span><span class="p">)</span>
<span class="n">F_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">F_train</span><span class="p">)</span>
<span class="n">F_valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">F_valid</span><span class="p">)</span>
<span class="n">dD_dr_train</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">dD_dr_train</span><span class="p">)</span>
<span class="n">dD_dr_valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">dD_dr_valid</span><span class="p">)</span>
</pre></div>
</div>
<p>Then let us define our model and loss function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">FFNet</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A simple feed-forward network with one hidden layer, randomly</span>
<span class="sd">    initialized weights, sigmoid activation and a linear output layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_features</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_out</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">FFNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_out</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>


<span class="k">def</span> <span class="nf">energy_force_loss</span><span class="p">(</span><span class="n">E_pred</span><span class="p">,</span> <span class="n">E_train</span><span class="p">,</span> <span class="n">F_pred</span><span class="p">,</span> <span class="n">F_train</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Custom loss function that targets both energies and forces.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">energy_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">E_pred</span> <span class="o">-</span> <span class="n">E_train</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">var_energy_train</span>
    <span class="n">force_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">F_pred</span> <span class="o">-</span> <span class="n">F_train</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">var_force_train</span>
    <span class="k">return</span> <span class="n">energy_loss</span> <span class="o">+</span> <span class="n">force_loss</span>


<span class="c1"># Initialize model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">FFNet</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_hidden</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_out</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># The Adam optimizer is used for training the model parameters</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
</pre></div>
</div>
<p>Now we can define the training loop that uses batches and early stopping to
prevent overfitting:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train!</span>
<span class="n">n_max_epochs</span> <span class="o">=</span> <span class="mi">5000</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">patience</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">i_worse</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">old_valid_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;Inf&quot;</span><span class="p">)</span>
<span class="n">best_valid_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;Inf&quot;</span><span class="p">)</span>

<span class="c1"># We explicitly require that the gradients should be calculated for the input</span>
<span class="c1"># variables. PyTorch will not do this by default as it is typically not needed.</span>
<span class="n">D_valid</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>

<span class="c1"># Epochs</span>
<span class="k">for</span> <span class="n">i_epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_max_epochs</span><span class="p">):</span>

    <span class="c1"># Batches</span>
    <span class="n">permutation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">D_train</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">D_train</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">):</span>

        <span class="n">indices</span> <span class="o">=</span> <span class="n">permutation</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">D_train_batch</span><span class="p">,</span> <span class="n">E_train_batch</span> <span class="o">=</span> <span class="n">D_train</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span> <span class="n">E_train</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="n">D_train_batch</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">F_train_batch</span><span class="p">,</span> <span class="n">dD_dr_train_batch</span> <span class="o">=</span> <span class="n">F_train</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span> <span class="n">dD_dr_train</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

        <span class="c1"># Forward pass: Predict energies from the descriptor input</span>
        <span class="n">E_train_pred_batch</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">D_train_batch</span><span class="p">)</span>

        <span class="c1"># Get derivatives of model output with respect to input variables. The</span>
        <span class="c1"># torch.autograd.grad-function can be used for this, as it returns the</span>
        <span class="c1"># gradients of the input with respect to outputs. It is very important</span>
        <span class="c1"># to set the create_graph=True in this case. Without it the derivatives</span>
        <span class="c1"># of the NN parameters with respect to the loss from the force error</span>
        <span class="c1"># will not be populated (=the force error will not affect the</span>
        <span class="c1"># training), but the model will still run fine without errors.</span>
        <span class="n">df_dD_train_batch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
            <span class="n">outputs</span><span class="o">=</span><span class="n">E_train_pred_batch</span><span class="p">,</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">D_train_batch</span><span class="p">,</span>
            <span class="n">grad_outputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">E_train_pred_batch</span><span class="p">),</span>
            <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Get derivatives of input variables (=descriptor) with respect to atom</span>
        <span class="c1"># positions = forces</span>
        <span class="n">F_train_pred_batch</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ijkl,il-&gt;ijk&#39;</span><span class="p">,</span> <span class="n">dD_dr_train_batch</span><span class="p">,</span> <span class="n">df_dD_train_batch</span><span class="p">)</span>

        <span class="c1"># Zero gradients, perform a backward pass, and update the weights.</span>
        <span class="c1"># D_train_batch.grad.data.zero_()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">energy_force_loss</span><span class="p">(</span><span class="n">E_train_pred_batch</span><span class="p">,</span> <span class="n">E_train_batch</span><span class="p">,</span> <span class="n">F_train_pred_batch</span><span class="p">,</span> <span class="n">F_train_batch</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

    <span class="c1"># Check early stopping criterion and save best model</span>
    <span class="n">E_valid_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">D_valid</span><span class="p">)</span>
    <span class="n">df_dD_valid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
        <span class="n">outputs</span><span class="o">=</span><span class="n">E_valid_pred</span><span class="p">,</span>
        <span class="n">inputs</span><span class="o">=</span><span class="n">D_valid</span><span class="p">,</span>
        <span class="n">grad_outputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">E_valid_pred</span><span class="p">),</span>
    <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">F_valid_pred</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ijkl,il-&gt;ijk&#39;</span><span class="p">,</span> <span class="n">dD_dr_valid</span><span class="p">,</span> <span class="n">df_dD_valid</span><span class="p">)</span>
    <span class="n">valid_loss</span> <span class="o">=</span> <span class="n">energy_force_loss</span><span class="p">(</span><span class="n">E_valid_pred</span><span class="p">,</span> <span class="n">E_valid</span><span class="p">,</span> <span class="n">F_valid_pred</span><span class="p">,</span> <span class="n">F_valid</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">valid_loss</span> <span class="o">&lt;</span> <span class="n">best_valid_loss</span><span class="p">:</span>
        <span class="c1"># print(&quot;Saving at epoch {}&quot;.format(i_epoch))</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s2">&quot;best_model.pt&quot;</span><span class="p">)</span>
        <span class="n">best_valid_loss</span> <span class="o">=</span> <span class="n">valid_loss</span>
    <span class="k">if</span> <span class="n">valid_loss</span> <span class="o">&gt;=</span> <span class="n">old_valid_loss</span><span class="p">:</span>
        <span class="n">i_worse</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">i_worse</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">i_worse</span> <span class="o">&gt;</span> <span class="n">patience</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Early stopping at epoch </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i_epoch</span><span class="p">))</span>
        <span class="k">break</span>
    <span class="n">old_valid_loss</span> <span class="o">=</span> <span class="n">valid_loss</span>

    <span class="k">if</span> <span class="n">i_epoch</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Finished epoch: </span><span class="si">{}</span><span class="s2"> with loss: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i_epoch</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
</pre></div>
</div>
<p>Once the model is trained (takes around thirty seconds), we can load the best
model and produce predicted data that is saved on disk for later analysis:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Way to tell pytorch that we are entering the evaluation phase</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;best_model.pt&quot;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="c1"># Calculate energies and force for the entire range</span>
<span class="n">E_whole</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">E_numpy</span><span class="p">)</span>
<span class="n">F_whole</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">F_numpy</span><span class="p">)</span>
<span class="n">dD_dr_whole</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">dD_dr_whole</span><span class="p">)</span>
<span class="n">D_whole</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">E_whole_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">D_whole</span><span class="p">)</span>
<span class="n">df_dD_whole</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
    <span class="n">outputs</span><span class="o">=</span><span class="n">E_whole_pred</span><span class="p">,</span>
    <span class="n">inputs</span><span class="o">=</span><span class="n">D_whole</span><span class="p">,</span>
    <span class="n">grad_outputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">E_whole_pred</span><span class="p">),</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">F_whole_pred</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s1">&#39;ijkl,il-&gt;ijk&#39;</span><span class="p">,</span> <span class="n">dD_dr_whole</span><span class="p">,</span> <span class="n">df_dD_whole</span><span class="p">)</span>
<span class="n">E_whole_pred</span> <span class="o">=</span> <span class="n">E_whole_pred</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">E_whole</span> <span class="o">=</span> <span class="n">E_whole</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="c1"># Save results for later analysis</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;r_train_full.npy&quot;</span><span class="p">,</span> <span class="n">r_train_full</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;E_train_full.npy&quot;</span><span class="p">,</span> <span class="n">E_train_full</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;F_train_full.npy&quot;</span><span class="p">,</span> <span class="n">F_train_full</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;E_whole_pred.npy&quot;</span><span class="p">,</span> <span class="n">E_whole_pred</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;F_whole_pred.npy&quot;</span><span class="p">,</span> <span class="n">F_whole_pred</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="analysis">
<h2>Analysis<a class="headerlink" href="#analysis" title="Link to this heading"></a></h2>
<p>In order to quickly assess the model performance, we will simply plot the model
response in the whole dataset input domain and compare it to the correct values
(full script in the GitHub repository:
<em>examples/forces_and_energies/analysis.py</em>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>

<span class="c1"># Load data as produded by the trained model</span>
<span class="n">r_whole</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;r.npy&quot;</span><span class="p">)</span>
<span class="n">r_train_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;r_train_full.npy&quot;</span><span class="p">)</span>
<span class="n">order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">r_whole</span><span class="p">)</span>
<span class="n">E_whole</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;E.npy&quot;</span><span class="p">)</span>
<span class="n">E_train_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;E_train_full.npy&quot;</span><span class="p">)</span>
<span class="n">E_whole_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;E_whole_pred.npy&quot;</span><span class="p">)</span>
<span class="n">F_whole</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;F.npy&quot;</span><span class="p">)</span>
<span class="n">F_train_full</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;F_train_full.npy&quot;</span><span class="p">)</span>
<span class="n">F_whole_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;F_whole_pred.npy&quot;</span><span class="p">)</span>
<span class="n">F_x_whole_pred</span> <span class="o">=</span> <span class="n">F_whole_pred</span><span class="p">[</span><span class="n">order</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">F_x_whole</span> <span class="o">=</span> <span class="n">F_whole</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">][</span><span class="n">order</span><span class="p">]</span>
<span class="n">F_x_train_full</span> <span class="o">=</span> <span class="n">F_train_full</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="c1"># Plot energies for the whole range</span>
<span class="n">order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">r_whole</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r_whole</span><span class="p">[</span><span class="n">order</span><span class="p">],</span> <span class="n">E_whole</span><span class="p">[</span><span class="n">order</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r_whole</span><span class="p">[</span><span class="n">order</span><span class="p">],</span> <span class="n">E_whole_pred</span><span class="p">[</span><span class="n">order</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Predicted&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Energy&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">mae_energy</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">E_whole_pred</span><span class="p">,</span> <span class="n">E_whole</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s2">&quot;MAE: </span><span class="si">{:.2}</span><span class="s2"> eV&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mae_energy</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">ax1</span><span class="o">.</span><span class="n">transAxes</span><span class="p">)</span>

<span class="c1"># Plot forces for whole range</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r_whole</span><span class="p">[</span><span class="n">order</span><span class="p">],</span> <span class="n">F_x_whole</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">r_whole</span><span class="p">[</span><span class="n">order</span><span class="p">],</span> <span class="n">F_x_whole_pred</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Predicted&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Distance&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Forces&#39;</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">mae_force</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">F_x_whole_pred</span><span class="p">,</span> <span class="n">F_x_whole</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s2">&quot;MAE: </span><span class="si">{:.2}</span><span class="s2"> eV/Å&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mae_force</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">ax2</span><span class="o">.</span><span class="n">transAxes</span><span class="p">)</span>

<span class="c1"># Plot training points</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">r_train_full</span><span class="p">,</span> <span class="n">E_train_full</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training points&quot;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">r_train_full</span><span class="p">,</span> <span class="n">F_x_train_full</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training points&quot;</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Show plot</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">left</span><span class="o">=</span><span class="mf">0.08</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">top</span><span class="o">=</span><span class="mf">0.97</span><span class="p">,</span> <span class="n">bottom</span><span class="o">=</span><span class="mf">0.08</span><span class="p">,</span> <span class="n">hspace</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>The plots look something like this:</p>
<a class="reference internal image-reference" href="../../_images/nn_test.png"><img alt="Lennard-Jones energies" class="align-center" src="../../_images/nn_test.png" style="width: 90%;" /></a>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../descriptors/valleoganov.html" class="btn btn-neutral float-left" title="Valle-Oganov descriptor" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="clustering.html" class="btn btn-neutral float-right" title="Unsupervised Learning: Clustering" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright .</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Versions</span>
      v: 2.1.x
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl id="version-table">
        <dt>Versions</dt>
      </dl>
    </div>
  </div>
<script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>